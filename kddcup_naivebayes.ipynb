{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "\n",
    "#importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importing the dataset\n",
    "col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"normal.\"]\n",
    "\n",
    "dataset = pd.read_csv(\"/Users/samanthawise/Documents/Bristol/MASTERS/Data Science Toolbox/Workshops/data/kddcup.data_10_percent.gz\", header=None, names = col_names)\n",
    "\n",
    "#change Multi-class to binary-class\n",
    "dataset['normal.'] = dataset['normal.'].replace(['back.', 'buffer_overflow.', 'ftp_write.', 'guess_passwd.', 'imap.', 'ipsweep.', 'land.', 'loadmodule.', 'multihop.', 'neptune.', 'nmap.', 'perl.', 'phf.', 'pod.', 'portsweep.', 'rootkit.', 'satan.', 'smurf.', 'spy.', 'teardrop.', 'warezclient.', 'warezmaster.'], 'attack')\n",
    "\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 41].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_x_1 = LabelEncoder()\n",
    "labelencoder_x_2 = LabelEncoder()\n",
    "labelencoder_x_3 = LabelEncoder()\n",
    "\n",
    "x[:, 1] = labelencoder_x_1.fit_transform(x[:, 1])\n",
    "x[:, 2] = labelencoder_x_2.fit_transform(x[:, 2])\n",
    "x[:, 3] = labelencoder_x_3.fit_transform(x[:, 3])\n",
    "\n",
    "onehotencoder_1 = OneHotEncoder(categorical_features = [1])\n",
    "x = onehotencoder_1.fit_transform(x).toarray()\n",
    "onehotencoder_2 = OneHotEncoder(categorical_features = [4])\n",
    "x = onehotencoder_2.fit_transform(x).toarray()\n",
    "onehotencoder_3 = OneHotEncoder(categorical_features = [70])\n",
    "x = onehotencoder_3.fit_transform(x).toarray()\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into the training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "#feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x_train = sc_x.fit_transform(x_train)\n",
    "x_test = sc_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9470755931236402"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Accuracy is: 0.9474248854642493\n",
      "Recall is : 0.78960349079871\n",
      "False Positive rate: 0.0002605336447758512\n",
      "Precision is: 0.9990055892740801\n",
      "F-measure is: 0.8820466242809566\n",
      "Entropy is: 0.0009939161356048137\n"
     ]
    }
   ],
   "source": [
    "#the performance of the classification model\n",
    "print(\"the Accuracy is: \"+ str((cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])))\n",
    "recall = cm[1,1]/(cm[0,1]+cm[1,1])\n",
    "print(\"Recall is : \"+ str(recall))\n",
    "print(\"False Positive rate: \"+ str(cm[1,0]/(cm[0,0]+cm[1,0])))\n",
    "precision = cm[1,1]/(cm[1,0]+cm[1,1])\n",
    "print(\"Precision is: \"+ str(precision))\n",
    "print(\"F-measure is: \"+ str(2*((precision*recall)/(precision+recall))))\n",
    "from math import log\n",
    "print(\"Entropy is: \"+ str(-precision*log(precision)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
