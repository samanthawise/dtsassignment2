---
title: "kddata_randomforest"
output: html_document
---

Random Forest algorithm is a classification algorithm based on ensemble learning. It works by building multiple decision trees at training and the developed decision trees forms the output
function.

Installing the necessary packages:

```{r}
library(randomForest)
library(caret)
library(e1071)
library(onehot)
```

Importing the data as a CSV and reformatting:

```{r}
kddata<-read.csv("//Users//samanthawise//Documents//VersionControl//datasciencetoolbox//assignment_1//data//kddcup.data_10_percent") # edit path

kddnames <- read.table("//Users//samanthawise//Documents//VersionControl//datasciencetoolbox//assignment_1//data//kddcup.names",sep=":",skip=1,as.is=T) # edit path

colnames(kddata) <- c(kddnames[,1],"label")

kddata$label <- as.character(kddata$label)
```

Encoding the categorical columns:

```{r}
kddata$protocol_type <- as.integer(factor(kddata$protocol_type))
kddata$service <- as.integer(factor(kddata$service))
kddata$flag <- as.integer(factor(kddata$flag))

# kddata$label <-onehot(kddata, cols = label, stringsAsFactors = TRUE) 
```


Creating the training-testing partitioning of the dataset:

```{r}
inTrain <- createDataPartition(y=kddata$label,p=0.5,list=FALSE)

kddata_normal <- kddata %>%
  filter(label == "normal.")

kddata_smurf <- kddata %>%
  filter(label == "smurf.")

kddata_attack <- kddata %>%
  filter(label != "normal." & label != "smurf.")

set.seed(1)

training_normal_amount <- floor(0.7*nrow(kddata)*0.2)
normal_amount <- sample(nrow(kddata_normal), training_normal_amount) 

training_normal <- kddata_normal[normal_amount,]
testing_normal <- kddata_normal[-normal_amount,]

training_attack_amount <- floor(0.7*nrow(kddata)*0.8)
testing_attack_amount <- floor(0.3*nrow(kddata)*0.8)
smurf_amount_train <- sample(nrow(kddata_smurf), training_attack_amount)
smurf_amount_test <- sample(nrow(kddata_smurf), testing_attack_amount)

training_attack1 <- kddata_smurf[smurf_amount,]
training_attack2 <- kddata_attack
testing_attack1 <- kddata %>%
  filter(label != "normal." & label != "smurf.")
testing_attack2 <- kddata_smurf[smurf_amount,]

training1 <- rbind(training_normal, training_attack1)
testing1 <- rbind(testing_normal, testing_attack1)

training2 <- rbind(training_normal, training_attack2)
testing2 <- rbind(testing_normal, testing_attack2)

training1$label[which(training1$label != 'normal.')] <- "attack."
testing1$label[which(testing1$label != 'normal.')] <- "attack."

training2$label[which(training2$label != 'normal.')] <- "attack."
testing2$label[which(testing2$label != 'normal.')] <- "attack."

training1$label <- factor(training1$label)
testing1$label <- factor(testing1$label)

training2$label <- factor(training2$label)
testing2$label <- factor(testing2$label)


kddata$label[which(kddata$label != 'normal.')] <- "attack."
kddata$label <- factor(kddata$label)

# write_csv(training, "training_kddata")
# write_csv(testing, "testing_kddata")
```

Taking a look at the entire dataset:

```{r}
str(kddata)
```

Training the model:

The training dataset contains 70% of the total datasize where 20% of that data contains "normal." traffic and the rest contain attack "smurf." traffic. The testing dataset contains the rest of the normal traffic and all the other attack types. 

```{r}
dim1 <-nrow(training1)
dim(training1)
t0 <- Sys.time()
output.forest1 <- randomForest(label ~ ., data = training1)
t1 <- Sys.time() - t0
print(paste("Classifier trained in",as.numeric(t1),"seconds", sep = " "))
```

This time the testing dataset (30% of total datasize) is broken down to 20% "normal." traffic data and the rest is "smurf." attack data. The training dataset contains the rest of the "normal." traffic and all the other attack types. 

```{r}
dim2 <-nrow(training2)
dim(training2)
t0 <- Sys.time()
output.forest2 <- randomForest(label ~ ., data = training2)
t1 <- Sys.time() - t0
print(paste("Classifier trained in",as.numeric(t1),"seconds", sep = " "))
```

The training and testing data is the whole dataset randomly split into half.

```{r}
training3 <- kddata[inTrain,]
testing3 <- kddata[-inTrain,]
dim3 <-nrow(training3)
dim(training3)
t0 <- Sys.time()
output.forest3 <- randomForest(label ~ ., data = training3)
t1 <- Sys.time() - t0
print(paste("Classifier trained in",as.numeric(t1),"seconds", sep = " "))
```

Printing out and plotting the model:

Smurf training.

```{r}
print(output.forest1)
plot (output.forest1)
```

Smurf testing.

```{r}
print(output.forest2)
plot (output.forest2)
```

50/50 split.

```{r}
print(output.forest3)
plot (output.forest3)
```

Predicting on the testing dataset:

Smurf training.

```{r}
pred1 <- predict(output.forest1,testing1)
confusionMatrix(pred1, testing1$label)
```

Smurf testing.

```{r}
pred2 <- predict(output.forest2,testing2)
confusionMatrix(pred2, testing2$label)
```

50/50 split.

```{r}
pred3 <- predict(output.forest3,testing3)
confusionMatrix(pred3, testing3$label)
```

